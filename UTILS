# ===============
# Core libraries
# ===============
import time  # Timing operations
import re    # Regular expressions

# ====================
# Computing and data manipulation
import numpy as np
import pandas as pd
# =====================

# ===================
# Excel I/O support
# ===================
import openpyxl  # Required for reading/writing .xlsx files

# ===================
# Graph theory and network analysis
# ==================
import networkx as nx

# =====================================
# SQLAlchemy for database connectivity
# =====================================
import sqlalchemy
from sqlalchemy import create_engine


# ------------------------------- One-Hot Encoding -------------------------------
def one_hot_encode(y, vocab_size):
    """
    Converts target labels into one-hot encoding.
    
    Parameters:
        y (array): Target labels of shape (batch_size,)
        vocab_size (int): Total number of possible words in the vocabulary.

    Returns:
        one_hot (array): One-hot encoded targets of shape (vocab_size, batch_size)
    """
    batch_size = len(y)
    one_hot = np.zeros((vocab_size, batch_size))  # Shape (vocab_size, batch_size)
    for i in range(batch_size):
        one_hot[y[i], i] = 1  # Set one-hot vector
    return one_hot
   
# ------------------------------ Clustering functions ---------------------------------
def compute_distance_matrix(embeddings):
    """
    Computes Euclidean distance matrix for clustering.
    """
    num_samples = embeddings.shape[0]
    distance_matrix = np.zeros((num_samples, num_samples))

    for i in range(num_samples):
        for j in range(num_samples):
            distance_matrix[i, j] = np.linalg.norm(embeddings[i] - embeddings[j])  # Euclidean distance

    return distance_matrix

def k_means_clustering(embeddings, k, max_iters):   # TODO: Optimize for stable centroid selection
    """
    Basic K-means clustering.
    """
    num_samples, embedding_dim = embeddings.shape
    centroids = embeddings[np.random.choice(num_samples, k, replace=False)]  # Randomly initialize centroids
    prev_assignments = np.zeros(num_samples)

    for iteration in range(max_iters):
        distances = np.array([[np.linalg.norm(e - c) for c in centroids] for e in embeddings])
        assignments = np.argmin(distances, axis=1)

        # Check for convergence
        if np.all(assignments == prev_assignments):
            break
        prev_assignments = assignments

        # Update centroids
        for cluster in range(k):
            cluster_points = embeddings[assignments == cluster]
            if len(cluster_points) > 0:
                centroids[cluster] = np.mean(cluster_points, axis=0)

    return assignments, centroids

# Dynamic Time Warping (DTW) function for distance computation
def dtw_distance(series1, series2):
    """Computes Dynamic Time Warping distance between two sequences."""
    n, m = len(series1), len(series2)
    dtw_matrix = np.full((n+1, m+1), np.inf)
    dtw_matrix[0, 0] = 0

    for i in range(1, n+1):
        for j in range(1, m+1):
            cost = abs(series1[i-1] - series2[j-1])
            dtw_matrix[i, j] = cost + min(dtw_matrix[i-1, j],    # Deletion
                                          dtw_matrix[i, j-1],    # Insertion
                                          dtw_matrix[i-1, j-1])  # Match

    return dtw_matrix[n, m]
